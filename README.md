# ğŸ“Š GPU Bandwidth Prediction

This project was developed as part of the *Probability and Statistics* course at HCMUT. It explores how statistical techniques and machine learning models can be used to analyze GPU hardware data and predict memory bandwidth.

## ğŸ§  Objective

To use both **descriptive** and **inferential statistics** to analyze GPU datasets, and to apply **regression models** to predict GPU memory bandwidth from hardware specifications.

## ğŸ“ Dataset

This project uses the [Computer Parts Dataset](https://www.kaggle.com/datasets/iliassekkaf/computerparts?resource=downlo) from Kaggle. It includes 3,406 GPU records with a variety of technical specifications and performance data.

Selected key columns:
- **Architecture**, **Boost_Clock**, **Core_Speed**, **Memory_Type**, **Memory_Speed**
- **DVI_Connection**, **HDMI_Connection**, **DisplayPort_Connection**, **VGA_Connection**
- **Integrated**, **Notebook_GPU**, **SLI_Crossfire**
- **L2_Cache**, **ROP**, **TMUs**, **Shader**, **Texture_Rate**
- **Release_Date**, **Release_Price**, **Power_Connector**, **Max_Power**, **PSU**
- **Open_GL**, **Direct_X**, **Resolution_WxH**, **Best_Resolution**
- **Memory_Bandwidth** (target variable)

> âš ï¸ Some columns contain missing values (e.g., `DisplayPort_Connection`, `HDMI_Connection`, `Shader`, `TMUs`) and were handled during preprocessing.

## ğŸ› ï¸ Methods Used

### ğŸ“ˆ Exploratory Data Analysis (EDA)
- Visualizations by vendor, architecture, and memory type using `seaborn`
- Distribution plots and correlation heatmaps for numeric features

### ğŸ§ª Statistical Testing
- **Normality Check**: Shapiro-Wilk Test  
- **Homogeneity of Variances**: Leveneâ€™s Test  
- **Group Mean Comparisons**:
  - Parametric: t-test, ANOVA  
  - Non-parametric: Kruskal-Wallis  
- **Post-hoc Analysis**: Dunn Test for identifying which group pairs differ significantly

### ğŸ¤– Machine Learning Models
- **Linear Regression**
- **Random Forest Regression**

### ğŸ“Š Evaluation Metrics
- **RÂ² Score**
- **Mean Squared Error (MSE)**

## âœ… Results

- **Random Forest Regressor** achieved:
  - **RÂ² Score**: 0.82  
  - **MSE**: 6.5
- Random Forest effectively captured non-linear relationships and outperformed Linear Regression.

## ğŸ” Key Findings
- GPU memory bandwidth is strongly influenced by memory type, memory speed, and bus width.
- Statistical testing revealed significant differences between GPU groups based on vendor and architecture.
- Random Forest showed robust performance across both training and test sets.

## ğŸ’» Technologies Used

- Python 3.x  
- Pandas, NumPy  
- Seaborn, Matplotlib  
- SciPy (for hypothesis testing)  
- Scikit-learn (for regression models)

## ğŸ“ Files

- `GPU_Analysis.ipynb` â€“ Full analysis and modeling notebook
- `README.md` â€“ Project overview and documentation
- `Report.pdf` â€“ Project report

## ğŸ”— Resources

- ğŸ“„ [Kaggle Dataset â€“ Computer Parts](https://www.kaggle.com/datasets/iliassekkaf/computerparts?resource=downlo)  


